package ui

import (
	"fmt"
	"os"
	"strings"
	"time"

	"github.com/axonops/cqlai/internal/ai"
	"github.com/axonops/cqlai/internal/config"
	"github.com/axonops/cqlai/internal/db"
	"github.com/axonops/cqlai/internal/logger"
	"github.com/axonops/cqlai/internal/router"
	"github.com/axonops/cqlai/internal/session"
	"github.com/axonops/cqlai/internal/ui/completion"

	"github.com/charmbracelet/bubbles/textinput"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
)

// ConnectionOptions holds command-line connection options
type ConnectionOptions struct {
	Host                string
	Port                int
	Keyspace            string
	Username            string
	Password            string
	RequireConfirmation bool
	ConnectTimeout      int    // Connection timeout in seconds
	RequestTimeout      int    // Request timeout in seconds
	Debug               bool   // Enable debug logging
	ConfigFile          string // Path to custom config file
	MCPAutoStart        bool   // Automatically start MCP server after connection
	MCPConfigFile       string // Path to MCP configuration JSON file
}

// AIMessage represents a single message in the AI conversation
type AIMessage struct {
	Role            string // "user", "assistant", or "system"
	Content         string // The raw message content (unwrapped)
	Type            string // Optional type like "cancelled", "selection", etc.
	SystemGenerated bool   // true if this message was generated by the system, not typed by user
}

// AISelectionResultMsg is sent when user completes a selection
type AISelectionResultMsg struct {
	Selection     string
	SelectionType string // The type of selection (e.g., "keyspace", "table")
	Cancelled     bool
}

// AIRequestUserSelectionMsg is sent when AI needs user to select from options
type AIRequestUserSelectionMsg struct {
	SelectionType string
	Options       []string
}

// AIRequestMoreInfoMsg is sent when AI needs more information from user
type AIRequestMoreInfoMsg struct {
	Message string
}

// AIInfoResponseMsg is sent when user provides additional information
type AIInfoResponseMsg struct {
	Response  string
	Cancelled bool
}

// MCPConfirmationTickMsg is sent periodically to check for pending MCP confirmations
type MCPConfirmationTickMsg struct{}

// mcpConfirmationTick returns a command that sends an MCPConfirmationTickMsg every 2 seconds
func mcpConfirmationTick() tea.Cmd {
	return tea.Tick(time.Second*2, func(t time.Time) tea.Msg {
		return MCPConfirmationTickMsg{}
	})
}

// MainModel is the main Bubble Tea model for the application.
type MainModel struct {
	historyViewport          viewport.Model // For command history
	tableViewport            viewport.Model // For current table display
	input                    textinput.Model
	topBar                   TopBarModel
	statusBar                StatusBarModel
	lastCommand              string
	commandHistory           []string
	historyIndex             int
	currentInput             string // Temporary storage for current input when navigating history
	fullHistoryContent       string // Full history content (not limited by viewport)
	clipboardBuffer          string // Buffer for cut/copy operations (Ctrl+K, Ctrl+U, Ctrl+Y)
	session                  *db.Session
	sessionManager           *session.Manager // Application state manager
	config                   *config.Config   // Full configuration
	aiConfig                 *config.AIConfig // AI configuration
	styles                   *Styles
	ready                    bool
	lastQueryTime            time.Duration
	rowCount                 int
	completionEngine         *completion.CompletionEngine
	completions              []string
	completionIndex          int
	showCompletions          bool
	completionScrollOffset   int // Track scroll position in completion list
	confirmExit              bool
	modal                    Modal
	aiConversationID         string              // Current AI conversation ID for stateful interactions
	aiSelectionModal         *AISelectionModal   // AI selection modal for user choices
	aiCQLModal               *AICQLModal         // AI CQL execution modal
	showHistoryModal         bool                // Whether to show command history modal
	historyModalIndex        int                 // Currently selected item in history modal
	historyModalScrollOffset int                 // Track scroll position in history modal
	horizontalOffset         int                 // For horizontal scrolling of tables
	lastTableData            [][]string          // Store the last table data for horizontal scrolling
	tableWidth               int                 // Width of the full table (before truncation)
	tableHeaders             []string            // Store column headers for sticky display
	columnWidths             []int               // Store column widths for proper alignment
	initialColumnWidths      []int               // Store initial column widths to maintain consistency
	hasTable                 bool                // Whether we're currently displaying a table
	cachedTableLines         []string            // Cache rendered table lines for fast scrolling
	navigationMode           bool                // Toggle between navigation keys and input mode
	viewMode                 string              // "history", "table", "trace", or "ai_info"
	showDataTypes            bool                // Whether to show column data types in table headers
	columnTypes              []string            // Store column data types
	tableRowBoundaries       []int               // Line numbers where table rows start
	
	// AI conversation view
	aiConversationActive     bool                // Whether AI conversation view is active
	aiConversationHistory    string              // Full conversation history (formatted)
	aiConversationMessages   []AIMessage         // Raw conversation messages for dynamic wrapping
	aiConversationViewport   viewport.Model      // Viewport for scrollable conversation
	aiConversationInput      textinput.Model     // Input for user messages
	aiProcessing            bool                // Whether AI is currently processing
	aiCommandHistory        []string            // Separate history for AI commands

	// Save modal
	saveModalActive         bool                // Whether save modal is active
	saveModalStep           int                 // 0: format selection, 1: filename input
	saveModalFormat         int                 // Selected format index (0: CSV, 1: JSON, 2: ASCII)
	saveModalFilename       string              // Filename being entered
	saveModalInput          textinput.Model     // Text input for filename
	aiHistoryIndex          int                 // Current position in AI history
	
	// Tracing support
	traceViewport            viewport.Model      // Viewport for trace results
	hasTrace                 bool                // Whether we have trace data to display
	traceData                [][]string          // Store trace results
	traceHeaders             []string            // Store trace column headers
	traceInfo                *db.TraceInfo       // Store trace session info
	traceHorizontalOffset    int                 // Horizontal scroll offset for trace table
	traceTableWidth          int                 // Full width of trace table
	traceColumnWidths        []int               // Column widths for trace table

	// Sliding window for large result sets
	slidingWindow *SlidingWindowTable // Manages memory-limited table data
	
	// Window dimensions
	windowWidth              int                 // Terminal window width
	windowHeight             int                 // Terminal window height

	// Multi-line mode
	multiLineMode   bool     // Whether we're in multi-line mode
	multiLineBuffer []string // Buffer for multi-line commands

	// History search
	historyManager            *HistoryManager
	aiHistoryManager          *HistoryManager // Separate history for AI conversations
	historySearchMode         bool     // Whether we're in Ctrl+R history search mode
	historySearchQuery        string   // Current search query
	historySearchResults      []string // Filtered history results
	historySearchIndex        int      // Currently selected item in search results
	historySearchScrollOffset int      // Scroll offset for history search modal
}

// wrapAIText wraps text to fit the AI conversation viewport width
func (m *MainModel) wrapAIText(text string) string {
	viewportWidth := m.aiConversationViewport.Width
	if viewportWidth == 0 {
		// Use history viewport width as fallback
		viewportWidth = m.historyViewport.Width
		if viewportWidth == 0 {
			viewportWidth = 80 // Default width
		}
	}
	// Leave some margin for better readability
	wrapWidth := viewportWidth - 5
	if wrapWidth < 20 {
		wrapWidth = 20 // Minimum wrap width
	}
	
	wrapStyle := lipgloss.NewStyle().Width(wrapWidth)
	return wrapStyle.Render(text)
}

// rebuildAIConversation rebuilds the formatted conversation from raw messages
func (m *MainModel) rebuildAIConversation() {
	var conversation string
	
	// Add header
	conversation = m.styles.AccentText.Render("AI Conversation") + "\n" + 
		m.styles.MutedText.Render("────────────────────") + "\n"
	
	// Format each message with current viewport width
	for _, msg := range m.aiConversationMessages {
		// Skip system-generated tool results (like "Found X tables matching")
		if msg.Role == "system" && msg.SystemGenerated {
			continue
		}

		switch msg.Role {
		case "user":
			// Extract just the user request from messages that include schema context
			displayContent := msg.Content
			if strings.Contains(msg.Content, "Available schema context:") && strings.Contains(msg.Content, "User request:") {
				// Extract just the user request part
				if idx := strings.Index(msg.Content, "User request: "); idx != -1 {
					displayContent = strings.TrimSpace(msg.Content[idx+len("User request: "):])
				}
			}

			wrappedContent := m.wrapAIText(displayContent)
			switch {
			case msg.Type == "selection":
				conversation += "\n" + m.styles.AccentText.Render("You selected: ") + wrappedContent + "\n\n"
			case msg.SystemGenerated:
				// System-generated retry messages
				conversation += "\n" + m.styles.MutedText.Render("System: ") + wrappedContent + "\n\n"
			default:
				conversation += "\n" + m.styles.AccentText.Render("You: ") + wrappedContent + "\n\n"
			}
		case "assistant":
			// Skip intermediate tool result messages
			if strings.HasPrefix(msg.Content, "Tool ") && strings.Contains(msg.Content, " result: ") {
				continue
			}
			wrappedContent := m.wrapAIText(msg.Content)
			// Check if this is an error message
			if len(msg.Content) > 6 && msg.Content[:6] == "Error:" {
				conversation += "\n" + m.styles.ErrorText.Render(wrappedContent) + "\n"
			} else {
				conversation += "\n" + m.styles.AccentText.Render("Assistant:") + "\n" + wrappedContent + "\n\n"
			}
		case "system":
			// System messages like "(Cancelled)"
			switch msg.Type {
			case "cancelled":
				conversation += m.styles.MutedText.Render("(Cancelled)") + "\n"
			case "selection_cancelled":
				conversation += m.styles.MutedText.Render("(Selection cancelled)") + "\n"
			}
		}
	}
	
	m.aiConversationHistory = conversation
	m.aiConversationViewport.SetContent(m.aiConversationHistory)
	m.aiConversationViewport.GotoBottom()
}

// NewMainModel creates a new MainModel.
func NewMainModel() (*MainModel, error) {
	return NewMainModelWithOptions(false)
}

// NewMainModelWithOptions creates a new MainModel with options.
func NewMainModelWithOptions(noConfirm bool) (*MainModel, error) {
	options := ConnectionOptions{
		RequireConfirmation: !noConfirm,
	}
	return NewMainModelWithConnectionOptions(options)
}

// autoStartMCPServer automatically starts the MCP server using configuration from file
func autoStartMCPServer(configFilePath string) error {
	// Load MCP config from file if provided
	var mcpConfig *MCPStartConfig
	var err error

	if configFilePath != "" {
		mcpConfig, err = LoadMCPConfig(configFilePath)
		if err != nil {
			return fmt.Errorf("failed to load MCP config from %s: %w", configFilePath, err)
		}
	} else {
		// Use defaults
		mcpConfig = DefaultMCPStartConfig()
	}

	// Build command string for MCP handler
	cmd := buildMCPStartCommand(mcpConfig)

	// Get MCP handler and start server
	mcpHandler := router.GetMCPHandler()
	if mcpHandler == nil {
		return fmt.Errorf("MCP handler not initialized")
	}

	result := mcpHandler.HandleMCPCommand(cmd)

	// Check if start was successful
	if strings.Contains(result, "started successfully") {
		return nil
	}

	return fmt.Errorf("MCP start failed: %s", result)
}

// NewMainModelWithConnectionOptions creates a new MainModel with connection options.
func NewMainModelWithConnectionOptions(options ConnectionOptions) (*MainModel, error) {
	ti := textinput.New()
	ti.Placeholder = "Enter CQL command..."
	ti.Focus()
	ti.CharLimit = 4096 // Increased to support long queries, especially from AI

	styles := DefaultStyles()

	ti.Prompt = styles.AccentText.Render("> ")
	ti.PlaceholderStyle = styles.MutedText

	infoReplyInput := textinput.New()
	infoReplyInput.Placeholder = "Type your response..."
	infoReplyInput.CharLimit = 4096 // Increased for consistency
	infoReplyInput.Width = 50

	// Load configuration from file and environment
	cfg, err := config.LoadConfig(options.ConfigFile)
	if err != nil {
		// Use defaults if config file not found
		cfg = &config.Config{
			Host:                "127.0.0.1",
			Port:                9042,
			RequireConfirmation: true,
			AI: &config.AIConfig{
				Provider: "mock",
			},
		}
	}
	
	// Enable debug logging if configured (from config file or command-line)
	if cfg.Debug || options.Debug {
		logger.SetDebugEnabled(true)
	}

	// Override with command-line options
	if options.Host != "" {
		cfg.Host = options.Host
	}
	if options.Port != 0 {
		cfg.Port = options.Port
	}
	if options.Keyspace != "" {
		cfg.Keyspace = options.Keyspace
	}
	if options.Username != "" {
		cfg.Username = options.Username
	}
	if options.Password != "" {
		cfg.Password = options.Password
	}
	// RequireConfirmation handled specially since false is a valid override
	if options.Host != "" || options.Port != 0 || options.Keyspace != "" ||
		options.Username != "" || options.Password != "" {
		cfg.RequireConfirmation = options.RequireConfirmation
	}

	dbSession, err := db.NewSessionWithOptions(db.SessionOptions{
		Host:           cfg.Host,
		Port:           cfg.Port,
		Keyspace:       cfg.Keyspace,
		Username:       cfg.Username,
		Password:       cfg.Password,
		Consistency:    cfg.Consistency,
		SSL:            cfg.SSL,
		ConnectTimeout: options.ConnectTimeout,
		RequestTimeout: options.RequestTimeout,
		ConfigFile:     options.ConfigFile,
	})
	if err != nil {
		return nil, err
	}

	// Create session manager for application state
	sessionMgr := session.NewManager(cfg)

	// Initialize router with session manager
	router.InitRouter(sessionMgr)

	// Initialize MCP handler
	if err := router.InitMCPHandler(dbSession); err != nil {
		// Log warning but don't fail - MCP features just won't be available
		fmt.Fprintf(os.Stderr, "Warning: could not initialize MCP handler: %v\n", err)
	}

	// Auto-start MCP server if requested
	if options.MCPAutoStart {
		if err := autoStartMCPServer(options.MCPConfigFile); err != nil {
			fmt.Fprintf(os.Stderr, "Warning: MCP auto-start failed: %v\n", err)
		} else {
			fmt.Fprintf(os.Stderr, "MCP server auto-started successfully\n")
		}
	}

	completionEngine := completion.NewCompletionEngine(dbSession, sessionMgr)

	// Initialize history manager with custom path from config if provided
	var historyManager *HistoryManager
	if cfg.HistoryFile != "" {
		historyManager, err = NewHistoryManagerWithPath(cfg.HistoryFile)
	} else {
		historyManager, err = NewHistoryManager()
	}
	if err != nil {
		// Log warning but don't fail - history will work in-memory only
		fmt.Fprintf(os.Stderr, "Warning: could not initialize history manager: %v\n", err)
		historyManager = &HistoryManager{history: []string{}}
	}

	// Initialize AI history manager (separate from CQL history) with custom path from config if provided
	var aiHistoryManager *HistoryManager
	if cfg.AIHistoryFile != "" {
		aiHistoryManager, err = NewAIHistoryManagerWithPath(cfg.AIHistoryFile)
	} else {
		aiHistoryManager, err = NewAIHistoryManager()
	}
	if err != nil {
		// Log warning but don't fail - AI history will work in-memory only
		fmt.Fprintf(os.Stderr, "Warning: could not initialize AI history manager: %v\n", err)
		aiHistoryManager = &HistoryManager{history: []string{}}
	}

	// Load command history from the history manager
	commandHistory := historyManager.GetHistory()
	
	// Load AI command history from the AI history manager
	aiCommandHistory := aiHistoryManager.GetHistory()

	// Initialize status bar with actual connection values
	statusBar := NewStatusBarModel()
	statusBar.Host = cfg.Host
	statusBar.Username = cfg.Username
	statusBar.Keyspace = cfg.Keyspace
	statusBar.Consistency = dbSession.Consistency()

	return &MainModel{
		topBar:                    NewTopBarModel(),
		statusBar:                 statusBar,
		input:                     ti,
		session:                   dbSession,
		sessionManager:            sessionMgr,
		config:                    cfg,
		aiConfig:                  cfg.AI,
		styles:                    styles,
		commandHistory:            commandHistory,
		historyIndex:              -1,
		fullHistoryContent:        "", // Will be initialized with welcome message in Init()
		completionEngine:          completionEngine,
		completions:               []string{},
		completionIndex:           -1,
		showCompletions:           false,
		completionScrollOffset:    0,
		horizontalOffset:          0,
		lastTableData:             nil,
		tableWidth:                0,
		tableHeaders:              nil,
		columnWidths:              nil,
		hasTable:                  false,
		viewMode:                  "history",
		hasTrace:                  false,
		traceData:                 nil,
		traceHeaders:              nil,
		historyManager:            historyManager,
		aiHistoryManager:          aiHistoryManager,
		aiCommandHistory:          aiCommandHistory,
		aiHistoryIndex:            -1,
		historySearchMode:         false,
		historySearchQuery:        "",
		historySearchResults:      []string{},
		historySearchIndex:        0,
		historySearchScrollOffset: 0,
	}, nil
}

// Init initializes the main model.
func (m *MainModel) Init() tea.Cmd {
	// Enable ONLY wheel button events (buttons 4 and 5)
	// This is a special mode that some terminals support
	// Standard button event mode but we'll try to be more specific
	fmt.Print("\x1b[?1000h") // Enable basic mouse tracking
	fmt.Print("\x1b[?1006h") // Use SGR encoding for larger coordinates
	return tea.Batch(textinput.Blink, mcpConfirmationTick())
}

// Update updates the main model.
func (m *MainModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	switch msg := msg.(type) {
	case tea.WindowSizeMsg:
		// Store the actual window dimensions
		m.windowWidth = msg.Width
		m.windowHeight = msg.Height
		
		headerHeight := 1 // top bar
		footerHeight := 1 // status bar
		inputHeight := 1  // text input
		newWidth := msg.Width
		newHeight := msg.Height - headerHeight - footerHeight - inputHeight

		if !m.ready {
			// Initialize viewports
			m.historyViewport = viewport.New(newWidth, newHeight)
			m.tableViewport = viewport.New(newWidth, newHeight)
			m.traceViewport = viewport.New(newWidth, newHeight)
			welcomeMsg := m.getWelcomeMessage()
			m.fullHistoryContent = welcomeMsg
			// Wrap content for initial display
			wrapped := m.wrapHistoryContent(newWidth)
			m.historyViewport.SetContent(wrapped)
			m.ready = true
		} else {
			// Resize viewports
			m.historyViewport.Width = newWidth
			m.historyViewport.Height = newHeight
			m.tableViewport.Width = newWidth
			m.tableViewport.Height = newHeight
			m.traceViewport.Width = newWidth
			m.traceViewport.Height = newHeight
			
			// Re-wrap history content for new width
			m.updateHistoryWrapping()
			
			// Also resize AI conversation viewport if it exists
			if m.aiConversationActive {
				m.aiConversationViewport.Width = newWidth
				m.aiConversationViewport.Height = newHeight
				// Rebuild the conversation with new width for dynamic wrapping
				if len(m.aiConversationMessages) > 0 {
					m.rebuildAIConversation()
				}
			}
		}

		m.input.Width = newWidth - 2 // Reduced margin for better scrolling
		// Also update AI conversation input width if initialized
		if m.aiConversationInput.Value() != "" || m.aiConversationActive {
			m.aiConversationInput.Width = newWidth - 2 // Reduced margin for better scrolling
		}
		return m, nil

	case tea.KeyMsg:
		updatedModel, cmd := m.handleKeyboardInput(msg)
		return updatedModel, cmd

	case tea.MouseMsg:
		updatedModel, cmd := m.handleMouseInput(msg)
		return updatedModel, cmd

	case AICQLResultMsg:
		// Handle AI CQL generation result
		logger.DebugfToFile("AI", "Received AI result message")

		// Store the conversation ID if provided
		if msg.ConversationID != "" {
			m.aiConversationID = msg.ConversationID
			logger.DebugfToFile("AI", "Conversation ID: %s", msg.ConversationID)

			// Sync conversation history from AI manager
			if history := ai.GetConversationHistory(msg.ConversationID); history != nil {
				// Clear and rebuild conversation messages from AI manager
				m.aiConversationMessages = []AIMessage{}
				for _, msg := range history {
					m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
						Role:            msg.Role,
						Content:         msg.Content,
						SystemGenerated: msg.SystemGenerated,
					})
				}
				logger.DebugfToFile("AI", "Synced %d messages from AI conversation history", len(history))
				// Rebuild the conversation view
				m.rebuildAIConversation()
			}
		}

		// Check if we're in AI conversation view mode waiting for response
		if m.viewMode == "ai" && m.aiConversationActive {
			if msg.Error != nil {
				// Check if this is an interaction request
				if interactionReq, ok := msg.Error.(*ai.InteractionRequest); ok {
					switch interactionReq.Type {
					case "selection":
						logger.DebugfToFile("AI", "User selection needed for: %s with %d options", interactionReq.SelectionType, len(interactionReq.SelectionOptions))
						logger.DebugfToFile("AI", "Selection options: %v", interactionReq.SelectionOptions)
						// Show selection modal
						m.aiSelectionModal = NewAISelectionModal(interactionReq.SelectionType, interactionReq.SelectionOptions)
						logger.DebugfToFile("AI", "Selection modal created: Active=%v, Options=%d", m.aiSelectionModal.Active, len(m.aiSelectionModal.Options))
						return m, nil
					case "info":
						logger.DebugfToFile("AI", "More info needed: %s", interactionReq.InfoMessage)
						// Add assistant message to raw messages
						m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
							Role:    "assistant",
							Content: interactionReq.InfoMessage,
						})
						// Rebuild the conversation with proper wrapping
						m.rebuildAIConversation()
						
						// Ensure we're in AI conversation view
						if !m.aiConversationActive {
							m.aiConversationActive = true
							m.viewMode = "ai"
						}
						m.aiConversationInput.Focus()
						m.aiProcessing = false
						return m, nil
					}
				}
				// Regular error
				logger.DebugfToFile("AI", "AI generation failed: %v", msg.Error)
				// Append error to conversation as assistant message
				errorMsg := fmt.Sprintf("Error: %v\n\nPlease try again or modify your query.", msg.Error)
				m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
					Role:    "assistant",
					Content: errorMsg,
				})
				m.rebuildAIConversation()
				m.aiConversationInput.Focus()
				m.aiProcessing = false
			} else {
				logger.DebugfToFile("AI", "AI generation successful")
				// Success - show the result in conversation
				resultText := ""
				switch {
				case msg.CQL != "":
					resultText = msg.CQL
					// Add assistant message to raw messages
					m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
						Role:    "assistant",
						Content: "Generated CQL:\n```sql\n" + resultText + "\n```",
					})
					// Rebuild the conversation with proper wrapping
					m.rebuildAIConversation()
					
					// Show the CQL execution modal
					m.aiCQLModal = NewAICQLModal(resultText)
					m.aiProcessing = false
					return m, nil
				case msg.Plan != nil && msg.Plan.Operation == "INFO":
					// For INFO operations, display the info content
					logger.DebugfToFile("AI", "INFO operation completed with content")
					if msg.Plan.InfoContent != "" {
						// Add assistant message to raw messages
						m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
							Role:    "assistant",
							Content: msg.Plan.InfoContent,
						})
					}
				case msg.Plan != nil:
					// Other operations
					resultText = fmt.Sprintf("Operation: %s", msg.Plan.Operation)
					if msg.Plan.Keyspace != "" {
						resultText += fmt.Sprintf("\nKeyspace: %s", msg.Plan.Keyspace)
					}
					if msg.Plan.Table != "" {
						resultText += fmt.Sprintf("\nTable: %s", msg.Plan.Table)
					}
					// Add assistant message to raw messages
					m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
						Role:    "assistant",
						Content: resultText,
					})
				}
				
				// Rebuild the conversation after adding messages
				m.rebuildAIConversation()
				// Stay in AI conversation view
				m.aiProcessing = false
			}
		}
		return m, nil

	case AIRequestUserSelectionMsg:
		// AI needs user to select from options
		logger.DebugfToFile("AI", "AI requesting user selection: type=%s, options=%v", msg.SelectionType, msg.Options)
		m.aiSelectionModal = NewAISelectionModal(msg.SelectionType, msg.Options)
		return m, nil

	case AISelectionResultMsg:
		// User completed selection (or cancelled)
		if msg.Cancelled {
			logger.DebugfToFile("AI", "User cancelled selection")
			// Add cancellation as system message
			m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
				Role: "system",
				Type: "selection_cancelled",
			})
			m.rebuildAIConversation()
			m.aiSelectionModal = nil
			m.aiProcessing = false
			m.aiConversationID = ""
		} else {
			logger.DebugfToFile("AI", "User selected %s: %s", msg.SelectionType, msg.Selection)
			// Add user selection as message
			m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
				Role:    "user",
				Content: msg.Selection,
				Type:    "selection",
			})
			m.rebuildAIConversation()
			
			// Clear selection modal
			m.aiSelectionModal = nil
			m.aiProcessing = true

			// Build contextual response with type information
			contextualResponse := fmt.Sprintf("User selected %s: %s", msg.SelectionType, msg.Selection)

			// Continue the existing conversation with the user's selection
			if m.aiConversationID != "" {
				logger.DebugfToFile("AI", "Continuing conversation %s with selection: %s", m.aiConversationID, contextualResponse)
				return m, continueAIConversation(m.aiConfig, m.aiConversationID, contextualResponse)
			} else {
				// Fallback if no conversation ID (shouldn't happen)
				logger.DebugfToFile("AI", "Warning: No conversation ID, starting new conversation")
				// Get the original request from conversation history
				contextualRequest := fmt.Sprintf("Previous context:\n%s\n\nUser selection: %s", m.aiConversationHistory, contextualResponse)
				return m, generateAICQL(m.session, m.aiConfig, contextualRequest)
			}
		}
		return m, nil

	case AIRequestMoreInfoMsg:
		// AI needs more information from user - append to conversation
		logger.DebugfToFile("AI", "AI requesting more info: %s", msg.Message)
		
		// Add assistant message to raw messages
		m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
			Role:    "assistant",
			Content: msg.Message,
		})
		// Rebuild the conversation with proper wrapping
		m.rebuildAIConversation()
		
		// Ensure we're in AI conversation view
		if !m.aiConversationActive {
			m.aiConversationActive = true
			m.viewMode = "ai"
		}
		m.aiConversationInput.Focus()
		m.aiProcessing = false
		
		// Close any modals
		return m, nil

	case AIInfoResponseMsg:
		// User provided additional information (or cancelled)
		if msg.Cancelled {
			logger.DebugfToFile("AI", "User cancelled info request")
			// Add cancellation as system message
			m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
				Role: "system",
				Type: "cancelled",
			})
			m.rebuildAIConversation()
			m.aiProcessing = false
			m.aiConversationID = ""
		} else {
			logger.DebugfToFile("AI", "User provided info: %s", msg.Response)
			// Add user response as message
			m.aiConversationMessages = append(m.aiConversationMessages, AIMessage{
				Role:    "user",
				Content: msg.Response,
			})
			m.rebuildAIConversation()

			// Set processing state
			m.aiProcessing = true

			// Continue the existing conversation with the additional info
			if m.aiConversationID != "" {
				logger.DebugfToFile("AI", "Continuing conversation %s with info: %s", m.aiConversationID, msg.Response)
				return m, continueAIConversation(m.aiConfig, m.aiConversationID, msg.Response)
			} else {
				// Fallback if no conversation ID (shouldn't happen)
				logger.DebugfToFile("AI", "Warning: No conversation ID, starting new conversation")
				// Use conversation history as context
				contextualRequest := fmt.Sprintf("Previous context:\n%s\n\nUser response: %s", m.aiConversationHistory, msg.Response)
				return m, generateAICQL(m.session, m.aiConfig, contextualRequest)
			}
		}
		return m, nil

	case MCPConfirmationTickMsg:
		// Poll MCP server for pending confirmations
		mcpHandler := router.GetMCPHandler()
		if mcpHandler != nil {
			pending := mcpHandler.GetPendingConfirmationCount()
			m.statusBar.PendingConfirmations = pending
		}
		// Schedule next tick
		return m, mcpConfirmationTick()
	}

	// Only update viewport for mouse wheel events
	switch msg.(type) {
	case tea.MouseMsg:
		var vpCmd tea.Cmd
		// Update the appropriate viewport based on mode
		switch {
		case m.viewMode == "trace" && m.hasTrace:
			m.traceViewport, vpCmd = m.traceViewport.Update(msg)
		case m.viewMode == "table" && m.hasTable:
			m.tableViewport, vpCmd = m.tableViewport.Update(msg)
		default:
			m.historyViewport, vpCmd = m.historyViewport.Update(msg)
		}
		m.input, _ = m.input.Update(msg)
		return m, vpCmd
	default:
		// Update input for other events
		var inputCmd tea.Cmd
		m.input, inputCmd = m.input.Update(msg)
		return m, inputCmd
	}
}
